{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Data Engineering Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Enviroment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import monotonically_increasing_id as mono_id\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dl.cfg'))\n",
    "\n",
    "INPUT_DATA = config['LOCAL']['INPUT_DATA']\n",
    "INPUT_DATA_VACCINES = config['LOCAL']['INPUT_DATA_VACCINES']\n",
    "OUTPUT_DATA = config['LOCAL']['OUTPUT_DATA']\n",
    "DATA_COLUMNS = config['COMMON']['DATA_COLUMNS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Spark session\n",
    "spark = SparkSession \\\n",
    "        .builder\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def write_parquet(df, parquet_name):\n",
    "    parquet_path = OUTPUT_DATA + f'{parquet_name}.parquet'\n",
    "    df.write.mode(\"overwrite\").parquet(parquet_path)\n",
    "    print(f'Writing {parquet_name} Table DONE.')\n",
    "    \n",
    "    # Read parquet file back to Spark\n",
    "    return spark.read.parquet(parquet_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1: Scope the Project and Gather Data\r\n",
    "In this step, weâ€™ll:\r\n",
    "\r\n",
    "* Identify and gather the data we'll be using for our project (at least two sources and more than 1 million rows).\r\n",
    "* Explain what end use cases we'd like to prepare the data for (e.g., analytics table, app back-end, source-of-truth database, etc.)\r\n",
    "\r\n",
    "We choose the following datasets:\r\n",
    "* Brazilian Government' dataset [COVID-19 population imunization program](https://dados.gov.br/dataset/covid-19-vacinacao/resource/ef3bd0b8-b605-474b-9ae5-c97390c197a8?inner_span=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- data_importacao_rnds: string (nullable = true)\n",
      " |-- document_id: string (nullable = true)\n",
      " |-- estabelecimento_municipio_codigo: string (nullable = true)\n",
      " |-- estabelecimento_municipio_nome: string (nullable = true)\n",
      " |-- estabelecimento_razaosocial: string (nullable = true)\n",
      " |-- estabelecimento_uf: string (nullable = true)\n",
      " |-- estabelecimento_valor: string (nullable = true)\n",
      " |-- estalecimento_nofantasia: string (nullable = true)\n",
      " |-- id_sistema_origem: string (nullable = true)\n",
      " |-- paciente_datanascimento: string (nullable = true)\n",
      " |-- paciente_endereco_cep: string (nullable = true)\n",
      " |-- paciente_endereco_coibgemunicipio: string (nullable = true)\n",
      " |-- paciente_endereco_copais: string (nullable = true)\n",
      " |-- paciente_endereco_nmmunicipio: string (nullable = true)\n",
      " |-- paciente_endereco_nmpais: string (nullable = true)\n",
      " |-- paciente_endereco_uf: string (nullable = true)\n",
      " |-- paciente_enumsexobiologico: string (nullable = true)\n",
      " |-- paciente_id: string (nullable = true)\n",
      " |-- paciente_idade: string (nullable = true)\n",
      " |-- paciente_nacionalidade_enumnacionalidade: string (nullable = true)\n",
      " |-- paciente_racacor_codigo: string (nullable = true)\n",
      " |-- paciente_racacor_valor: string (nullable = true)\n",
      " |-- sistema_origem: string (nullable = true)\n",
      " |-- vacina_categoria_codigo: string (nullable = true)\n",
      " |-- vacina_categoria_nome: string (nullable = true)\n",
      " |-- vacina_codigo: string (nullable = true)\n",
      " |-- vacina_dataaplicacao: string (nullable = true)\n",
      " |-- vacina_descricao_dose: string (nullable = true)\n",
      " |-- vacina_fabricante_nome: string (nullable = true)\n",
      " |-- vacina_fabricante_referencia: string (nullable = true)\n",
      " |-- vacina_grupoatendimento_codigo: string (nullable = true)\n",
      " |-- vacina_grupoatendimento_nome: string (nullable = true)\n",
      " |-- vacina_lote: string (nullable = true)\n",
      " |-- vacina_nome: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vaccines_df = spark.read.csv(INPUT_DATA_VACCINES, sep=';', header=True)\n",
    "\n",
    "vaccines_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 2: Explore and Assess the Data\r\n",
    "In this step we need:\r\n",
    "* Explore the data to identify data quality issues, like missing values, duplicate data, etc.\r\n",
    "* Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['paciente_id', 'paciente_idade', 'paciente_datanascimento',\n",
       "       'paciente_enumsexobiologico', 'paciente_endereco_nmpais',\n",
       "       'paciente_endereco_uf', 'paciente_endereco_nmmunicipio',\n",
       "       'estabelecimento_razaosocial', 'estalecimento_nofantasia',\n",
       "       'estabelecimento_uf', 'estabelecimento_municipio_nome',\n",
       "       'vacina_categoria_codigo', 'vacina_categoria_nome',\n",
       "       'vacina_grupoatendimento_codigo', 'vacina_grupoatendimento_nome',\n",
       "       'vacina_fabricante_nome', 'vacina_codigo', 'vacina_nome',\n",
       "       'vacina_dataaplicacao'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data dictionary from JSON and extract the valid columns\n",
    "col_names = pd.read_json(DATA_COLUMNS, typ='series')\n",
    "valid_columns = col_names.index\n",
    "valid_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sistema_origem',\n",
       " 'paciente_endereco_copais',\n",
       " 'id_sistema_origem',\n",
       " 'paciente_racacor_valor',\n",
       " 'paciente_racacor_codigo',\n",
       " 'estabelecimento_municipio_codigo',\n",
       " 'vacina_fabricante_referencia',\n",
       " 'paciente_endereco_coibgemunicipio',\n",
       " 'paciente_nacionalidade_enumnacionalidade',\n",
       " 'estabelecimento_valor',\n",
       " 'vacina_descricao_dose',\n",
       " 'paciente_endereco_cep',\n",
       " 'vacina_lote',\n",
       " 'data_importacao_rnds',\n",
       " 'document_id']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the difference between the dataframe colums and the valid columns\n",
    "columns_todrop = list(set(vaccines_df.columns) - set(valid_columns))\n",
    "\n",
    "columns_todrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- estabelecimento_municipio_nome: string (nullable = true)\n",
      " |-- estabelecimento_razaosocial: string (nullable = true)\n",
      " |-- estabelecimento_uf: string (nullable = true)\n",
      " |-- estalecimento_nofantasia: string (nullable = true)\n",
      " |-- paciente_datanascimento: string (nullable = true)\n",
      " |-- paciente_endereco_nmmunicipio: string (nullable = true)\n",
      " |-- paciente_endereco_nmpais: string (nullable = true)\n",
      " |-- paciente_endereco_uf: string (nullable = true)\n",
      " |-- paciente_enumsexobiologico: string (nullable = true)\n",
      " |-- paciente_id: string (nullable = true)\n",
      " |-- paciente_idade: string (nullable = true)\n",
      " |-- vacina_categoria_codigo: string (nullable = true)\n",
      " |-- vacina_categoria_nome: string (nullable = true)\n",
      " |-- vacina_codigo: string (nullable = true)\n",
      " |-- vacina_dataaplicacao: string (nullable = true)\n",
      " |-- vacina_fabricante_nome: string (nullable = true)\n",
      " |-- vacina_grupoatendimento_codigo: string (nullable = true)\n",
      " |-- vacina_grupoatendimento_nome: string (nullable = true)\n",
      " |-- vacina_nome: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove unused columns from dataframe\n",
    "vaccines_df = vaccines_df.drop(*columns_todrop)\n",
    "vaccines_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Replace the null values\n",
    "vaccines_df = vaccines_df.fillna(\\\n",
    "    {\\\n",
    "        'vacina_categoria_codigo': 0, \\\n",
    "        'vacina_categoria_nome': 'N/A', \\\n",
    "        'vacina_grupoatendimento_nome': 'N/A', \\\n",
    "        'paciente_enumsexobiologico': 'N/A',\\\n",
    "        'estalecimento_nofantasia': 'N/A'\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 3: Define the Data Model\r\n",
    "* Map out the conceptual data model and explain why you chose that model\r\n",
    "* List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 4: Run ETL to Model the Data\r\n",
    "* Create the data pipelines and the data model\r\n",
    "* Include a data dictionary\r\n",
    "* Run data quality checks to ensure the pipeline ran as expected\r\n",
    "\t* Integrity constraints on the relational database (e.g., unique key, data type, etc.)\r\n",
    "\t* Unit tests for the scripts to ensure they are doing the right thing\r\n",
    "\t* Source/count checks to ensure completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- supplier: string (nullable = true)\n",
      "\n",
      "+---+--------------------+--------------------+\n",
      "| id|                name|            supplier|\n",
      "+---+--------------------+--------------------+\n",
      "| 86|Covid-19-Coronava...|   FUNDACAO BUTANTAN|\n",
      "| 85|Vacina Covid-19 -...|FUNDACAO OSWALDO ...|\n",
      "+---+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create vaccines table and write parquet files\n",
    "vaccines_df.createOrReplaceTempView(\"vaccines_table_DF\")\n",
    "vaccines_table_DF = spark.sql(\"\"\"\n",
    "    SELECT  DISTINCT vacina_codigo AS id, \n",
    "                     vacina_nome AS name, \n",
    "                     vacina_fabricante_nome AS supplier\n",
    "    FROM vaccines_table_DF\n",
    "    ORDER BY supplier\n",
    "\"\"\")\n",
    "\n",
    "vaccines_table_DF.printSchema()\n",
    "vaccines_table_DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing vaccines Table DONE.\n"
     ]
    }
   ],
   "source": [
    "# Write parquet file and get back to Spark:\n",
    "vaccines_table_DF = write_parquet(vaccines_table_DF, 'vaccines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = false)\n",
      " |-- organization: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+-----+-------------------+\n",
      "|                name|        organization|state|               city|\n",
      "+--------------------+--------------------+-----+-------------------+\n",
      "|AMBULATORIO MUNIC...|PREFEITURA MUNICI...|   MA|    POCAO DE PEDRAS|\n",
      "|CEADIM DE SERRANO...|MUNICIPIO DE SERR...|   MA|SERRANO DO MARANHAO|\n",
      "|CENTRO DE ATENDIM...|PREFEITURA MUNICI...|   MA|      VARGEM GRANDE|\n",
      "|CENTRO DE ESPECIA...|PREFEITURA MUNICI...|   MA|    BARAO DE GRAJAU|\n",
      "|CENTRO DE ESPECIA...|PREFEITURA MUNICI...|   MA|           PINHEIRO|\n",
      "|CENTRO DE SAUDE A...|MUNICIPIO DE URBA...|   MA|      URBANO SANTOS|\n",
      "|CENTRO DE SAUDE A...|PREFEITURA MUNICI...|   MA| SAO VICENTE FERRER|\n",
      "|CENTRO DE SAUDE A...|PREFEITURA MUNICI...|   MA|    GODOFREDO VIANA|\n",
      "|CENTRO DE SAUDE A...|PREFEITURA MUNICI...|   MA|           CURURUPU|\n",
      "|CENTRO DE SAUDE B...|PREFEITURA MUNICI...|   MA|            BACABAL|\n",
      "|CENTRO DE SAUDE C...|PREFEITURA MUNICI...|   MA|      LAGOA DO MATO|\n",
      "|CENTRO DE SAUDE C...|PREFEITURA MUNICI...|   MA|         CANTANHEDE|\n",
      "|CENTRO DE SAUDE C...|PREFEITURA MUNICI...|   MA|            BACABAL|\n",
      "|CENTRO DE SAUDE C...|PREFEITURA MUNICI...|   MA|           CURURUPU|\n",
      "|CENTRO DE SAUDE D...|PREFEITURA MUNICI...|   MA|          MATA ROMA|\n",
      "|CENTRO DE SAUDE D...|PREFEITURA MUNICI...|   MA|            BACABAL|\n",
      "|CENTRO DE SAUDE D...|PREFEITURA MUNICI...|   MA|      ALDEIAS ALTAS|\n",
      "|CENTRO DE SAUDE D...|PREFEITURA MUNICI...|   MA|     CANDIDO MENDES|\n",
      "|CENTRO DE SAUDE D...|PREFEITURA MUNICI...|   MA|            COROATA|\n",
      "|CENTRO DE SAUDE D...|PREFEITURA MUNICI...|   MA|         MARACACUME|\n",
      "+--------------------+--------------------+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Health Institution table and write parquet files\n",
    "vaccines_df.createOrReplaceTempView(\"health_institution_table_DF\")\n",
    "health_institution_table_DF = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT estalecimento_nofantasia AS name,\n",
    "                    estabelecimento_razaosocial AS organization,\n",
    "                    estabelecimento_uf AS state,\n",
    "                    estabelecimento_municipio_nome AS city\n",
    "    FROM health_institution_table_DF\n",
    "    ORDER BY name\n",
    "\"\"\")\n",
    "\n",
    "health_institution_table_DF.withColumn(\"id\", mono_id())\n",
    "health_institution_table_DF.printSchema()\n",
    "health_institution_table_DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing health_institution Table DONE.\n"
     ]
    }
   ],
   "source": [
    "# Write parquet file and get back to Spark:\n",
    "health_institution_table_DF = write_parquet(health_institution_table_DF, 'health_institution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = false)\n",
      " |-- name: string (nullable = false)\n",
      "\n",
      "+---+--------------------+\n",
      "| id|                name|\n",
      "+---+--------------------+\n",
      "|  1|        Comorbidades|\n",
      "|  2|        Faixa EtÃ¡ria|\n",
      "| 11|Pessoas com Defic...|\n",
      "|  3|Pessoas de 60 ano...|\n",
      "|  7|     Povos IndÃ­genas|\n",
      "|  6|Povos e Comunidad...|\n",
      "|  9|Trabalhadores de ...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Category table and write parquet files\n",
    "vaccines_df.createOrReplaceTempView(\"category_table_DF\")\n",
    "category_table_DF = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT vacina_categoria_codigo AS id,\n",
    "                    vacina_categoria_nome AS name\n",
    "            FROM category_table_DF\n",
    "            ORDER BY name\n",
    "\"\"\")\n",
    "\n",
    "category_table_DF.printSchema()\n",
    "category_table_DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing category Table DONE.\n"
     ]
    }
   ],
   "source": [
    "# Write parquet file and get back to Spark:\n",
    "category_table_DF = write_parquet(category_table_DF, 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = false)\n",
      "\n",
      "+----+--------------------+\n",
      "|  id|                name|\n",
      "+----+--------------------+\n",
      "| 905|  Cuidador de Idosos|\n",
      "| 103|   Diabetes Mellitus|\n",
      "| 105|DoenÃ§a Renal CrÃ´nica|\n",
      "| 106|DoenÃ§as Cardiovas...|\n",
      "| 907|       Enfermeiro(a)|\n",
      "| 909|     Fisioterapeutas|\n",
      "| 911|FuncionÃ¡rio do Si...|\n",
      "| 107|HipertensÃ£o de di...|\n",
      "| 102|          Neoplasias|\n",
      "| 915|       Nutricionista|\n",
      "| 926|              Outros|\n",
      "|1102|Pessoas com Defic...|\n",
      "| 201|Pessoas de 18 a 6...|\n",
      "| 301|Pessoas de 60 ano...|\n",
      "| 202|Pessoas de 65 a 6...|\n",
      "| 203|Pessoas de 70 a 7...|\n",
      "| 204|Pessoas de 75 a 7...|\n",
      "| 205|Pessoas de 80 ano...|\n",
      "| 701|Povos indÃ­genas e...|\n",
      "| 917|Profissionais e A...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Population Groups table and write parquet files\n",
    "vaccines_df.createOrReplaceTempView(\"population_group_table_DF\")\n",
    "population_group_table_DF = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT vacina_grupoatendimento_codigo AS id,\n",
    "                    vacina_grupoatendimento_nome AS name\n",
    "            FROM population_group_table_DF\n",
    "        ORDER BY name\n",
    "\"\"\")\n",
    "\n",
    "population_group_table_DF.printSchema()\n",
    "population_group_table_DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing population_group Table DONE.\n"
     ]
    }
   ],
   "source": [
    "# Write parquet file and get back to Spark:\n",
    "population_group_table_DF = write_parquet(population_group_table_DF, 'population_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- birthdate: string (nullable = true)\n",
      " |-- gender: string (nullable = false)\n",
      " |-- country: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n",
      "+--------------------+---+-------------------+------+-------+-----+--------------------+\n",
      "|                  id|age|          birthdate|gender|country|state|                city|\n",
      "+--------------------+---+-------------------+------+-------+-----+--------------------+\n",
      "|001172d8023bf74e8...| 69|1951-05-03 00:00:00|     M| BRASIL|   MA|            SAO LUIS|\n",
      "|0037915f9d8c82740...| 80|1940-07-14 00:00:00|     F| BRASIL|   MA|          ACAILANDIA|\n",
      "|003f0c135c70c7f4d...| 82|1938-05-09 00:00:00|     F| BRASIL|   MA|  ITINGA DO MARANHAO|\n",
      "|00ba3b39629b28be3...| 61|1960-01-21 00:00:00|     F| BRASIL|   MA|      BARRA DO CORDA|\n",
      "|012c38283b39186dd...| 50|1970-04-03 00:00:00|     M| BRASIL|   MA|       PRIMEIRA CRUZ|\n",
      "|014d4147b3c1cde08...| 33|1987-07-23 00:00:00|     F| BRASIL|   MA|                CODO|\n",
      "|027b0944c938c2ea1...|100|1920-10-15 00:00:00|     F| BRASIL|   MA|     PASSAGEM FRANCA|\n",
      "|03440bfb7fb9eb83b...| 78|1942-09-24 00:00:00|     M| BRASIL|   MA|       PINDARE-MIRIM|\n",
      "|034ecb4f868ba1aad...| 66|1954-08-03 00:00:00|     M| BRASIL|   MA|            PINHEIRO|\n",
      "|03beb365a9b88eeda...| 76|1944-04-08 00:00:00|     M| BRASIL|   MA|              GRAJAU|\n",
      "|043cf7bdc819b9a8f...| 70|1950-07-06 00:00:00|     F| BRASIL|   MA|            SAO LUIS|\n",
      "|044b42ef0a290b2b0...| 75|1945-09-05 00:00:00|     M| BRASIL|   MA|            ESTREITO|\n",
      "|04d4de9c5084ee7f3...| 75|1946-02-01 00:00:00|     F| BRASIL|   MA|          ACAILANDIA|\n",
      "|04febc31e2f007c5e...| 68|1953-02-17 00:00:00|     M| BRASIL|   MA|            PINHEIRO|\n",
      "|051b1a6670aa42a13...| 35|1985-08-24 00:00:00|     M| BRASIL|   MA|        PALMEIRANDIA|\n",
      "|0594c311726297d81...| 88|1933-01-10 00:00:00|     M| BRASIL|   MA|               TIMON|\n",
      "|05e418aea32620567...| 40|1981-02-10 00:00:00|     M| BRASIL|   MA|          SANTA INES|\n",
      "|05ec6de7defe295a7...| 76|1945-01-14 00:00:00|     M| BRASIL|   MA|SANTA QUITERIA DO...|\n",
      "|063a0c777546ca648...| 27|1993-08-28 00:00:00|     M| BRASIL|   MA|              BACURI|\n",
      "|074197230cabbabc7...| 69|1951-05-07 00:00:00|     M| BRASIL|   MA|            SAO LUIS|\n",
      "+--------------------+---+-------------------+------+-------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Patient table and write parquet files\n",
    "vaccines_df.createOrReplaceTempView(\"patient_table_DF\")\n",
    "patient_table_DF = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT paciente_id AS id,\n",
    "                    paciente_idade AS age,\n",
    "                    paciente_datanascimento AS birthdate,\n",
    "                    paciente_enumsexobiologico AS gender,\n",
    "                    paciente_endereco_nmpais AS country,\n",
    "                    paciente_endereco_uf AS state,\n",
    "                    paciente_endereco_nmmunicipio AS city\n",
    "            FROM patient_table_DF\n",
    "            WHERE paciente_id IS NOT NULL\n",
    "            ORDER BY id\n",
    "\"\"\")\n",
    "\n",
    "patient_table_DF.printSchema()\n",
    "patient_table_DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing patient Table DONE.\n"
     ]
    }
   ],
   "source": [
    "# Write parquet file and get back to Spark:\n",
    "patient_table_DF = write_parquet(patient_table_DF, 'patient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e3babd7ac79e0887df5a9e3ee8123f217b43f09743b73590444977beefbb8a7a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
