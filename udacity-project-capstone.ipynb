{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Engineering Capstone Project"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Enviroment setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Import necessary libraries\r\n",
    "import pandas as pd\r\n",
    "from pyspark.sql import SparkSession\r\n",
    "from pyspark.sql.functions import monotonically_increasing_id as mono_id\r\n",
    "import configparser"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Read config file\r\n",
    "config = configparser.ConfigParser()\r\n",
    "config.read_file(open('dl.cfg'))\r\n",
    "\r\n",
    "INPUT_DATA = config['LOCAL']['INPUT_DATA']\r\n",
    "INPUT_DATA_VACCINES = config['LOCAL']['INPUT_DATA_VACCINES']\r\n",
    "OUTPUT_DATA = config['LOCAL']['OUTPUT_DATA']\r\n",
    "DATA_COLUMNS = config['COMMON']['DATA_COLUMNS']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Spark session\r\n",
    "spark = SparkSession \\\r\n",
    "        .builder\\\r\n",
    "        .getOrCreate()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Scope the Project and Gather Data\r\n",
    "In this step, weâ€™ll:\r\n",
    "\r\n",
    "* Identify and gather the data we'll be using for our project (at least two sources and more than 1 million rows).\r\n",
    "* Explain what end use cases we'd like to prepare the data for (e.g., analytics table, app back-end, source-of-truth database, etc.)\r\n",
    "\r\n",
    "We choose the following datasets:\r\n",
    "* Brazilian Government' dataset [COVID-19 population imunization program](https://dados.gov.br/dataset/covid-19-vacinacao/resource/ef3bd0b8-b605-474b-9ae5-c97390c197a8?inner_span=True)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "vaccines_df = spark.read.csv(INPUT_DATA_VACCINES, sep=';', header=True)\r\n",
    "\r\n",
    "vaccines_df.printSchema()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- document_id: string (nullable = true)\n",
      " |-- paciente_id: string (nullable = true)\n",
      " |-- paciente_idade: string (nullable = true)\n",
      " |-- paciente_datanascimento: string (nullable = true)\n",
      " |-- paciente_enumsexobiologico: string (nullable = true)\n",
      " |-- paciente_racacor_codigo: string (nullable = true)\n",
      " |-- paciente_racacor_valor: string (nullable = true)\n",
      " |-- paciente_endereco_coibgemunicipio: string (nullable = true)\n",
      " |-- paciente_endereco_copais: string (nullable = true)\n",
      " |-- paciente_endereco_nmmunicipio: string (nullable = true)\n",
      " |-- paciente_endereco_nmpais: string (nullable = true)\n",
      " |-- paciente_endereco_uf: string (nullable = true)\n",
      " |-- paciente_endereco_cep: string (nullable = true)\n",
      " |-- paciente_nacionalidade_enumnacionalidade: string (nullable = true)\n",
      " |-- estabelecimento_valor: string (nullable = true)\n",
      " |-- estabelecimento_razaosocial: string (nullable = true)\n",
      " |-- estalecimento_nofantasia: string (nullable = true)\n",
      " |-- estabelecimento_municipio_codigo: string (nullable = true)\n",
      " |-- estabelecimento_municipio_nome: string (nullable = true)\n",
      " |-- estabelecimento_uf: string (nullable = true)\n",
      " |-- vacina_grupoatendimento_codigo: string (nullable = true)\n",
      " |-- vacina_grupoatendimento_nome: string (nullable = true)\n",
      " |-- vacina_categoria_codigo: string (nullable = true)\n",
      " |-- vacina_categoria_nome: string (nullable = true)\n",
      " |-- vacina_lote: string (nullable = true)\n",
      " |-- vacina_fabricante_nome: string (nullable = true)\n",
      " |-- vacina_fabricante_referencia: string (nullable = true)\n",
      " |-- vacina_dataaplicacao: string (nullable = true)\n",
      " |-- vacina_descricao_dose: string (nullable = true)\n",
      " |-- vacina_codigo: string (nullable = true)\n",
      " |-- vacina_nome: string (nullable = true)\n",
      " |-- sistema_origem: string (nullable = true)\n",
      " |-- data_importacao_rnds: string (nullable = true)\n",
      " |-- id_sistema_origem: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Explore and Assess the Data\r\n",
    "In this step we need:\r\n",
    "* Explore the data to identify data quality issues, like missing values, duplicate data, etc.\r\n",
    "* Document steps necessary to clean the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Read the data dictionary from JSON and extract the valid columns\r\n",
    "col_names = pd.read_json(DATA_COLUMNS, typ='series')\r\n",
    "valid_columns = col_names.index.to_list()\r\n",
    "valid_columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['paciente_id',\n",
       " 'paciente_idade',\n",
       " 'paciente_datanascimento',\n",
       " 'paciente_enumsexobiologico',\n",
       " 'paciente_endereco_nmpais',\n",
       " 'paciente_endereco_uf',\n",
       " 'paciente_endereco_nmmunicipio',\n",
       " 'estabelecimento_razaosocial',\n",
       " 'estalecimento_nofantasia',\n",
       " 'estabelecimento_uf',\n",
       " 'estabelecimento_municipio_nome',\n",
       " 'vacina_categoria_codigo',\n",
       " 'vacina_categoria_nome',\n",
       " 'vacina_grupoatendimento_codigo',\n",
       " 'vacina_grupoatendimento_nome',\n",
       " 'vacina_fabricante_nome',\n",
       " 'vacina_codigo',\n",
       " 'vacina_nome',\n",
       " 'vacina_dataaplicacao']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Get the difference between the dataframe colums and the valid columns\r\n",
    "columns_todrop = list(set(vaccines_df.columns) - set(valid_columns))\r\n",
    "\r\n",
    "columns_todrop"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['vacina_descricao_dose',\n",
       " 'paciente_endereco_coibgemunicipio',\n",
       " 'sistema_origem',\n",
       " 'data_importacao_rnds',\n",
       " 'paciente_nacionalidade_enumnacionalidade',\n",
       " 'estabelecimento_municipio_codigo',\n",
       " 'paciente_racacor_valor',\n",
       " 'document_id',\n",
       " 'paciente_racacor_codigo',\n",
       " 'paciente_endereco_copais',\n",
       " 'vacina_lote',\n",
       " 'vacina_fabricante_referencia',\n",
       " 'estabelecimento_valor',\n",
       " 'paciente_endereco_cep',\n",
       " 'id_sistema_origem']"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Remove unused columns from dataframe\r\n",
    "vaccines_df = vaccines_df.drop(*columns_todrop)\r\n",
    "vaccines_df.printSchema()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- paciente_id: string (nullable = true)\n",
      " |-- paciente_idade: string (nullable = true)\n",
      " |-- paciente_datanascimento: string (nullable = true)\n",
      " |-- paciente_enumsexobiologico: string (nullable = true)\n",
      " |-- paciente_endereco_nmmunicipio: string (nullable = true)\n",
      " |-- paciente_endereco_nmpais: string (nullable = true)\n",
      " |-- paciente_endereco_uf: string (nullable = true)\n",
      " |-- estabelecimento_razaosocial: string (nullable = true)\n",
      " |-- estalecimento_nofantasia: string (nullable = true)\n",
      " |-- estabelecimento_municipio_nome: string (nullable = true)\n",
      " |-- estabelecimento_uf: string (nullable = true)\n",
      " |-- vacina_grupoatendimento_codigo: string (nullable = true)\n",
      " |-- vacina_grupoatendimento_nome: string (nullable = true)\n",
      " |-- vacina_categoria_codigo: string (nullable = true)\n",
      " |-- vacina_categoria_nome: string (nullable = true)\n",
      " |-- vacina_fabricante_nome: string (nullable = true)\n",
      " |-- vacina_dataaplicacao: string (nullable = true)\n",
      " |-- vacina_codigo: string (nullable = true)\n",
      " |-- vacina_nome: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Replace the null values\r\n",
    "vaccines_df = vaccines_df.fillna(\\\r\n",
    "    {\\\r\n",
    "        'vacina_categoria_codigo': 0, \\\r\n",
    "        'vacina_categoria_nome': 'N/A', \\\r\n",
    "        'vacina_grupoatendimento_nome': 'N/A', \\\r\n",
    "        'paciente_enumsexobiologico': 'N/A',\\\r\n",
    "        'estalecimento_nofantasia': 'N/A'\r\n",
    "    })"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Define the Data Model\r\n",
    "* Map out the conceptual data model and explain why you chose that model\r\n",
    "* List the steps necessary to pipeline the data into the chosen data model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Run ETL to Model the Data\r\n",
    "* Create the data pipelines and the data model\r\n",
    "* Include a data dictionary\r\n",
    "* Run data quality checks to ensure the pipeline ran as expected\r\n",
    "\t* Integrity constraints on the relational database (e.g., unique key, data type, etc.)\r\n",
    "\t* Unit tests for the scripts to ensure they are doing the right thing\r\n",
    "\t* Source/count checks to ensure completeness"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Create vaccines table and write parquet files\r\n",
    "vaccines_df.createOrReplaceTempView(\"vaccines_table_DF\")\r\n",
    "vaccines_table_DF = spark.sql(\"\"\"\r\n",
    "    SELECT  DISTINCT vacina_codigo AS id, \r\n",
    "                     vacina_nome AS name, \r\n",
    "                     vacina_fabricante_nome AS supplier\r\n",
    "    FROM vaccines_table_DF\r\n",
    "    ORDER BY supplier\r\n",
    "\"\"\")\r\n",
    "\r\n",
    "vaccines_table_DF.printSchema()\r\n",
    "vaccines_table_DF.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- supplier: string (nullable = true)\n",
      "\n",
      "+---+--------------------+--------------------+\n",
      "| id|                name|            supplier|\n",
      "+---+--------------------+--------------------+\n",
      "| 87|Vacina covid-19 -...|BioNTech/Fosun Ph...|\n",
      "| 86|Covid-19-Coronava...|   FUNDACAO BUTANTAN|\n",
      "| 86|Covid-19-Coronava...|FUNDACAO OSWALDO ...|\n",
      "| 85|Vacina Covid-19 -...|FUNDACAO OSWALDO ...|\n",
      "| 88|Vacina covid-19 -...|       Janssen-Cilag|\n",
      "| 87|Vacina covid-19 -...| MINISTERIO DA SAUDE|\n",
      "| 89|Covid-19-AstraZeneca| MINISTERIO DA SAUDE|\n",
      "| 88|Vacina covid-19 -...| MINISTERIO DA SAUDE|\n",
      "| 86|Covid-19-Coronava...|SERUM INSTITUTE O...|\n",
      "| 85|Vacina Covid-19 -...|SINOVAC LIFE SCIE...|\n",
      "+---+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "vaccines_table_path = OUTPUT_DATA + \"vaccines_table.parquet\"\r\n",
    "vaccines_table_DF.write.mode(\"overwrite\").parquet(vaccines_table_path)\r\n",
    "print(\"Writing Vaccines Table DONE.\")\r\n",
    "\r\n",
    "# Read parquet file back to Spark:\r\n",
    "vaccines_table_DF = spark.read.parquet(vaccines_table_path)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Writing Vaccines Table DONE.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Create Health Institution table and write parquet files\r\n",
    "vaccines_df.createOrReplaceTempView(\"health_institution_table_DF\")\r\n",
    "health_institution_table_DF = spark.sql(\"\"\"\r\n",
    "    SELECT DISTINCT estalecimento_nofantasia AS name,\r\n",
    "                    estabelecimento_razaosocial AS organization,\r\n",
    "                    estabelecimento_uf AS state,\r\n",
    "                    estabelecimento_municipio_nome AS city\r\n",
    "    FROM health_institution_table_DF\r\n",
    "    ORDER BY name\r\n",
    "\"\"\")\r\n",
    "\r\n",
    "health_institution_table_DF.withColumn(\"id\", mono_id())\r\n",
    "health_institution_table_DF.printSchema()\r\n",
    "health_institution_table_DF.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- nome: string (nullable = false)\n",
      " |-- razaosocial: string (nullable = true)\n",
      " |-- uf: string (nullable = true)\n",
      " |-- municipio: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+---+--------------------+\n",
      "|                nome|         razaosocial| uf|           municipio|\n",
      "+--------------------+--------------------+---+--------------------+\n",
      "|AMBULATORIO MUNIC...|PREFEITURA MUNICI...| MA|     POCAO DE PEDRAS|\n",
      "|C SAUDE BACELAR V...|PREFEITURA MUNICI...| MA|           PIRAPEMAS|\n",
      "|CEADIM DE SERRANO...|MUNICIPIO DE SERR...| MA| SERRANO DO MARANHAO|\n",
      "|CENTRO DE ATENDIM...|PREFEITURA MUNICI...| MA|       VARGEM GRANDE|\n",
      "|CENTRO DE ATENDIM...|PREFEITURA MUNICI...| MA|  ITINGA DO MARANHAO|\n",
      "|CENTRO DE ATENDIM...|PREFEITURA MUNICI...| MA|              MONCAO|\n",
      "|CENTRO DE ESPECIA...|PREFEITURA MUNICI...| MA|     BARAO DE GRAJAU|\n",
      "|CENTRO DE ESPECIA...|PREFEITURA MUNICI...| MA|            PINHEIRO|\n",
      "|CENTRO DE PARTO N...|PREFEITURA MUNICI...| MA|          BURITICUPU|\n",
      "|CENTRO DE REFEREN...|PREFEITURA MUNICI...| MA|            TIMBIRAS|\n",
      "|CENTRO DE SAUDE 1...|PREFEITURA MUNICI...| MA|           PARNARAMA|\n",
      "|CENTRO DE SAUDE A...|PREFEITURA MUNICI...| MA|    CACHOEIRA GRANDE|\n",
      "|CENTRO DE SAUDE A...|MUNICIPIO DE URBA...| MA|       URBANO SANTOS|\n",
      "|CENTRO DE SAUDE A...|PREFEITURA MUNICI...| MA|             BACABAL|\n",
      "|CENTRO DE SAUDE A...|PREFEITURA MUNICI...| MA|       LAGO DO JUNCO|\n",
      "|CENTRO DE SAUDE A...|PREFEITURA MUNICI...| MA|             BACABAL|\n",
      "|CENTRO DE SAUDE AMAR|SECRETARIA MUNICI...| MA|            SAO LUIS|\n",
      "|CENTRO DE SAUDE A...|PREFEITURA MUNICI...| MA|  SAO VICENTE FERRER|\n",
      "|CENTRO DE SAUDE A...|PREFEITURA MUNICI...| MA|FORTALEZA DOS NOG...|\n",
      "|CENTRO DE SAUDE A...|PREFEITURA MUNICI...| MA|        BURITI BRAVO|\n",
      "+--------------------+--------------------+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "health_institution_path = OUTPUT_DATA + \"health_institution.parquet\"\r\n",
    "health_institution_table_DF.write.mode(\"overwrite\").parquet(health_institution_path)\r\n",
    "print(\"Writing Health Institution Table DONE.\")\r\n",
    "\r\n",
    "# Read parquet file back to Spark:\r\n",
    "health_institution_table_DF = spark.read.parquet(health_institution_path)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Writing Health Institution Table DONE.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Create Category table and write parquet files\r\n",
    "vaccines_df.createOrReplaceTempView(\"category_table_DF\")\r\n",
    "category_table_DF = spark.sql(\"\"\"\r\n",
    "    SELECT DISTINCT vacina_categoria_codigo AS id,\r\n",
    "                    vacina_categoria_nome AS name\r\n",
    "            FROM category_table_DF\r\n",
    "            ORDER BY name\r\n",
    "\"\"\")\r\n",
    "\r\n",
    "category_table_DF.printSchema()\r\n",
    "category_table_DF.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- id: string (nullable = false)\n",
      " |-- name: string (nullable = false)\n",
      "\n",
      "+---+--------------------+\n",
      "| id|                name|\n",
      "+---+--------------------+\n",
      "|  1|        Comorbidades|\n",
      "|  2|        Faixa EtÃ¡ria|\n",
      "|  4|ForÃ§as Armadas (m...|\n",
      "|  5|ForÃ§as de Seguran...|\n",
      "| 14|FuncionÃ¡rio do Si...|\n",
      "| 21|           Gestantes|\n",
      "| -1|                 N/A|\n",
      "|114|              Outros|\n",
      "| 11|Pessoas com Defic...|\n",
      "|  3|Pessoas de 60 ano...|\n",
      "| 12|Pessoas em SituaÃ§...|\n",
      "| 15|PopulaÃ§Ã£o Privada...|\n",
      "|  7|     Povos IndÃ­genas|\n",
      "|  6|Povos e Comunidad...|\n",
      "| 25|           PuÃ©rperas|\n",
      "| 16|Trabalhadores Ind...|\n",
      "| 13|Trabalhadores Por...|\n",
      "|  8|Trabalhadores da ...|\n",
      "| 94|Trabalhadores de ...|\n",
      "|  9|Trabalhadores de ...|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "category_path = OUTPUT_DATA + \"category.parquet\"\r\n",
    "category_table_DF.write.mode(\"overwrite\").parquet(category_path)\r\n",
    "print(\"Writing Category Table DONE.\")\r\n",
    "\r\n",
    "# Read parquet file back to Spark:\r\n",
    "category_table_DF = spark.read.parquet(category_path)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Writing Category Table DONE.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Create Population Groups table and write parquet files\r\n",
    "vaccines_df.createOrReplaceTempView(\"population_group_table_DF\")\r\n",
    "population_group_table_DF = spark.sql(\"\"\"\r\n",
    "    SELECT DISTINCT vacina_grupoatendimento_codigo AS id,\r\n",
    "                    vacina_grupoatendimento_nome AS name\r\n",
    "            FROM population_group_table_DF\r\n",
    "        ORDER BY name\r\n",
    "\"\"\")\r\n",
    "\r\n",
    "population_group_table_DF.printSchema()\r\n",
    "population_group_table_DF.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = false)\n",
      "\n",
      "+------+--------------------+\n",
      "|    id|                name|\n",
      "+------+--------------------+\n",
      "|000929|AcadÃªmicos/estuda...|\n",
      "|000931|Agente ComunitÃ¡ri...|\n",
      "|000930|Agente de Combate...|\n",
      "|001006|          AquaviÃ¡rio|\n",
      "|000922|   Assistente Social|\n",
      "|000927|Auxiliar de Enfer...|\n",
      "|000901|Auxiliar de Veter...|\n",
      "|000932|Auxiliar em SaÃºde...|\n",
      "|001001|               AÃ©reo|\n",
      "|000903|           BiomÃ©dico|\n",
      "|000902|             BiÃ³logo|\n",
      "|000501|      Bombeiro Civil|\n",
      "|000502|    Bombeiro Militar|\n",
      "|001002|        Caminhoneiro|\n",
      "|000114|    Cirrose hepÃ¡tica|\n",
      "|001003|Coletivo RodoviÃ¡r...|\n",
      "|000904|Cozinheiro e Auxi...|\n",
      "|000905|  Cuidador de Idosos|\n",
      "|000103|   Diabetes Mellitus|\n",
      "|000105|DoenÃ§a Renal CrÃ´nica|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "population_group_path = OUTPUT_DATA + \"population_group.parquet\"\r\n",
    "population_group_table_DF.write.mode(\"overwrite\").parquet(population_group_path)\r\n",
    "print(\"Writing Population Group Table DONE.\")\r\n",
    "\r\n",
    "# Read parquet file back to Spark:\r\n",
    "population_group_table_DF = spark.read.parquet(population_group_path)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Writing Population Group Table DONE.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Create Patient table and write parquet files\r\n",
    "vaccines_df.createOrReplaceTempView(\"patient_table_DF\")\r\n",
    "patient_table_DF = spark.sql(\"\"\"\r\n",
    "    SELECT DISTINCT paciente_id AS id,\r\n",
    "\t\t\t\t\tpaciente_idade AS age,\r\n",
    "\t\t\t\t\tpaciente_datanascimento AS birthdate,\r\n",
    "\t\t\t\t\tpaciente_enumsexobiologico AS gender,\r\n",
    "\t\t\t\t\tpaciente_endereco_nmpais AS country,\r\n",
    "\t\t\t\t\tpaciente_endereco_uf AS state,\r\n",
    "\t\t\t\t\tpaciente_endereco_nmmunicipio AS city\r\n",
    "\t\t\tFROM patient_table_DF\r\n",
    "\t\t\tWHERE paciente_id IS NOT NULL\r\n",
    "\t\t\tORDER BY id\r\n",
    "\"\"\")\r\n",
    "\r\n",
    "patient_table_DF.printSchema()\r\n",
    "patient_table_DF.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- birthdate: string (nullable = true)\n",
      " |-- gender: string (nullable = false)\n",
      " |-- country: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n",
      "+--------------------+---+----------+------+-------+-----+--------------------+\n",
      "|                  id|age| birthdate|gender|country|state|                city|\n",
      "+--------------------+---+----------+------+-------+-----+--------------------+\n",
      "|0000073e1d449a8f1...| 57|1963-11-03|     M| BRASIL|   MA|            SAO LUIS|\n",
      "|00000c2cb8d0d6da8...| 38|1982-08-19|     F| BRASIL|   MA|          IMPERATRIZ|\n",
      "|00000ee6399e2172e...| 39|1982-02-14|     F| BRASIL|   MA|            SAO LUIS|\n",
      "|0000146ec1364d3a4...| 25|1995-09-15|     F| BRASIL|   MA|            SAO LUIS|\n",
      "|0000196ea219c99b3...| 33|1988-03-22|     M| BRASIL|   MA|      PACO DO LUMIAR|\n",
      "|00001f5e735f9336e...| 31|1990-04-29|     M| BRASIL|   PI|            TERESINA|\n",
      "|000021cece03820ab...| 38|1982-09-24|     M| BRASIL|   MA|FORMOSA DA SERRA ...|\n",
      "|000025290e0d13e39...| 72|1948-12-20|     M| BRASIL|   PI|            PARNAIBA|\n",
      "|00002ed57ee11f694...| 73|1947-12-08|     M| BRASIL|   MA|     ITAPECURU MIRIM|\n",
      "|00004048665fa7966...| 29|1991-12-02|     F| BRASIL|   MA|       LAGO DA PEDRA|\n",
      "|0000512507433b89d...| 40|1980-10-18|     F| BRASIL|   MA|              GRAJAU|\n",
      "|0000528cb2f3c40bd...| 26|1995-03-03|     F| BRASIL|   MA|            SAO LUIS|\n",
      "|000052d5ede67acaa...| 46|1974-08-04|     F| BRASIL|   MA|        AFONSO CUNHA|\n",
      "|0000566bab2772372...| 29|1992-04-13|     M| BRASIL|   MT|              CUIABA|\n",
      "|0000572bf104caf9b...| 44|1976-12-01|     F| BRASIL|   MA|               TIMON|\n",
      "|00005bc6f1f172eb8...| 84|1936-07-26|     F| BRASIL|   MA|          ACAILANDIA|\n",
      "|00005bd5c883c8f69...| 48|1972-12-13|     M| BRASIL|   MA|JENIPAPO DOS VIEIRAS|\n",
      "|00006aa943825c492...| 57|1964-06-02|     M| BRASIL|   MA|               ARAME|\n",
      "|00006fc69d69d1fdb...| 37|1983-12-14|     F| BRASIL|   MA|       PINDARE-MIRIM|\n",
      "|000070d671037aa94...| 45|1975-10-05|     M| BRASIL|   MA|           PARAIBANO|\n",
      "+--------------------+---+----------+------+-------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "patient_path = OUTPUT_DATA + \"patient.parquet\"\r\n",
    "patient_table_DF.write.mode(\"overwrite\").parquet(patient_path)\r\n",
    "print(\"Writing Patient Table DONE.\")\r\n",
    "\r\n",
    "# Read parquet file back to Spark:\r\n",
    "patient_table_DF = spark.read.parquet(patient_path)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Writing Patient Table DONE.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e3babd7ac79e0887df5a9e3ee8123f217b43f09743b73590444977beefbb8a7a"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}