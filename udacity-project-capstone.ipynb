{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Engineering Capstone Project"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Enviroment setup"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import necessary libraries\r\n",
    "import pandas as pd\r\n",
    "from pyspark.sql import SparkSession\r\n",
    "from pyspark.sql.functions import row_number\r\n",
    "from pyspark.sql.window import Window\r\n",
    "import configparser"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Read config file\r\n",
    "config = configparser.ConfigParser()\r\n",
    "config.read_file(open('dl.cfg'))\r\n",
    "\r\n",
    "INPUT_DATA = config['LOCAL']['INPUT_DATA']\r\n",
    "INPUT_DATA_VACCINES = config['LOCAL']['INPUT_DATA_VACCINES']\r\n",
    "OUTPUT_DATA = config['LOCAL']['OUTPUT_DATA']\r\n",
    "DATA_COLUMNS = config['COMMON']['DATA_COLUMNS']"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Spark session\r\n",
    "spark = SparkSession \\\r\n",
    "        .builder\\\r\n",
    "        .getOrCreate()"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def write_parquet(df, parquet_name):\r\n",
    "    parquet_path = OUTPUT_DATA + f'{parquet_name}.parquet'\r\n",
    "    df.write.mode(\"overwrite\").parquet(parquet_path)\r\n",
    "    print(f'Writing {parquet_name} Table DONE.')\r\n"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def read_parquet(parquet_name):\r\n",
    "    parquet_path = OUTPUT_DATA + f'{parquet_name}.parquet'\r\n",
    "    return spark.read.parquet(parquet_path)"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Scope the Project and Gather Data\n",
    "In this step, weâ€™ll:\n",
    "\n",
    "* Identify and gather the data we'll be using for our project (at least two sources and more than 1 million rows).\n",
    "* Explain what end use cases we'd like to prepare the data for (e.g., analytics table, app back-end, source-of-truth database, etc.)\n",
    "\n",
    "We choose the following datasets:\n",
    "* Brazilian Government' dataset [COVID-19 population imunization program](https://dados.gov.br/dataset/covid-19-vacinacao/resource/ef3bd0b8-b605-474b-9ae5-c97390c197a8?inner_span=True)"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vaccines_df = spark.read.csv(INPUT_DATA_VACCINES, sep=';', header=True)\r\n",
    "\r\n",
    "vaccines_df.printSchema()"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Explore and Assess the Data\n",
    "In this step we need:\n",
    "* Explore the data to identify data quality issues, like missing values, duplicate data, etc.\n",
    "* Document steps necessary to clean the data"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Read the data dictionary from JSON and extract the valid columns\r\n",
    "col_names = pd.read_json(DATA_COLUMNS, typ='series')\r\n",
    "valid_columns = col_names.index\r\n",
    "valid_columns"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get the difference between the dataframe colums and the valid columns\r\n",
    "columns_todrop = list(set(vaccines_df.columns) - set(valid_columns))\r\n",
    "\r\n",
    "columns_todrop"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remove unused columns from dataframe\r\n",
    "vaccines_df = vaccines_df.drop(*columns_todrop)\r\n",
    "vaccines_df.printSchema()"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Replace the null values\r\n",
    "vaccines_df = vaccines_df.fillna(\\\r\n",
    "    {\\\r\n",
    "        'vacina_categoria_codigo': 0, \\\r\n",
    "        'vacina_categoria_nome': 'N/A', \\\r\n",
    "        'vacina_grupoatendimento_nome': 'N/A', \\\r\n",
    "        'paciente_enumsexobiologico': 'N/A',\\\r\n",
    "        'estalecimento_nofantasia': 'N/A'\r\n",
    "    })"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Define the Data Model\n",
    "* Map out the conceptual data model and explain why you chose that model\n",
    "* List the steps necessary to pipeline the data into the chosen data model"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Run ETL to Model the Data\n",
    "* Create the data pipelines and the data model\n",
    "* Include a data dictionary\n",
    "* Run data quality checks to ensure the pipeline ran as expected\n",
    "\t* Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    "\t* Unit tests for the scripts to ensure they are doing the right thing\n",
    "\t* Source/count checks to ensure completeness"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create vaccines table and write parquet files\r\n",
    "vaccines_df.createOrReplaceTempView(\"vaccines_table_DF\")\r\n",
    "vaccines_table_DF = spark.sql(\"\"\"\r\n",
    "    SELECT  DISTINCT vacina_codigo AS id, \r\n",
    "                     vacina_nome AS name, \r\n",
    "                     vacina_fabricante_nome AS supplier\r\n",
    "    FROM vaccines_table_DF\r\n",
    "    ORDER BY supplier\r\n",
    "\"\"\")\r\n",
    "\r\n",
    "vaccines_table_DF.printSchema()\r\n",
    "vaccines_table_DF.show()"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write parquet file and get back to Spark:\r\n",
    "write_parquet(vaccines_table_DF, 'vaccines')\r\n",
    "vaccines_table_DF = read_parquet('vaccines')"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create Health Institution table and write parquet files\r\n",
    "vaccines_df.createOrReplaceTempView(\"health_institution_table_DF\")\r\n",
    "health_institution_table_DF = spark.sql(\"\"\"\r\n",
    "    SELECT DISTINCT estalecimento_nofantasia AS name,\r\n",
    "                    estabelecimento_razaosocial AS organization,\r\n",
    "                    estabelecimento_uf AS state,\r\n",
    "                    estabelecimento_municipio_nome AS city\r\n",
    "    FROM health_institution_table_DF\r\n",
    "    ORDER BY name\r\n",
    "\"\"\")\r\n",
    "\r\n",
    "window = Window.orderBy(health_institution_table_DF.columns)\r\n",
    "health_institution_table_DF = health_institution_table_DF.select(row_number().over(window).alias('id'), '*')\r\n",
    "health_institution_table_DF.printSchema()\r\n",
    "health_institution_table_DF.show()"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write parquet file and get back to Spark:\r\n",
    "write_parquet(health_institution_table_DF, 'health_institution')\r\n",
    "health_institution_table_DF = read_parquet('health_institution')"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create Category table and write parquet files\r\n",
    "vaccines_df.createOrReplaceTempView(\"category_table_DF\")\r\n",
    "category_table_DF = spark.sql(\"\"\"\r\n",
    "    SELECT DISTINCT vacina_categoria_codigo AS id,\r\n",
    "                    vacina_categoria_nome AS name\r\n",
    "            FROM category_table_DF\r\n",
    "            ORDER BY name\r\n",
    "\"\"\")\r\n",
    "\r\n",
    "category_table_DF.printSchema()\r\n",
    "category_table_DF.show()"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write parquet file and get back to Spark:\r\n",
    "write_parquet(category_table_DF, 'category')\r\n",
    "category_table_DF = read_parquet('category')"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create Population Groups table and write parquet files\r\n",
    "vaccines_df.createOrReplaceTempView(\"population_group_table_DF\")\r\n",
    "population_group_table_DF = spark.sql(\"\"\"\r\n",
    "    SELECT DISTINCT vacina_grupoatendimento_codigo AS id,\r\n",
    "                    vacina_grupoatendimento_nome AS name\r\n",
    "            FROM population_group_table_DF\r\n",
    "        ORDER BY name\r\n",
    "\"\"\")\r\n",
    "\r\n",
    "population_group_table_DF.printSchema()\r\n",
    "population_group_table_DF.show()"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write parquet file and get back to Spark:\r\n",
    "write_parquet(population_group_table_DF, 'population_group')\r\n",
    "population_group_table_DF = read_parquet('population_group')"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create Patient table and write parquet files\r\n",
    "vaccines_df.createOrReplaceTempView(\"patient_table_DF\")\r\n",
    "patient_table_DF = spark.sql(\"\"\"\r\n",
    "    SELECT DISTINCT paciente_id AS id,\r\n",
    "                    paciente_idade AS age,\r\n",
    "                    paciente_datanascimento AS birthdate,\r\n",
    "                    paciente_enumsexobiologico AS gender,\r\n",
    "                    paciente_endereco_nmpais AS country,\r\n",
    "                    paciente_endereco_uf AS state,\r\n",
    "                    paciente_endereco_nmmunicipio AS city\r\n",
    "            FROM patient_table_DF\r\n",
    "            WHERE paciente_id IS NOT NULL\r\n",
    "            ORDER BY id\r\n",
    "\"\"\")\r\n",
    "\r\n",
    "patient_table_DF.printSchema()\r\n",
    "patient_table_DF.show()"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write parquet file and get back to Spark:\r\n",
    "write_parquet(patient_table_DF, 'patient')\r\n",
    "patient_table_DF = read_parquet('patient')"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vaccines_df_joined = vaccines_df.join(health_institution_table_DF, \\\r\n",
    "                                      [vaccines_df.estalecimento_nofantasia == health_institution_table_DF.name,\\\r\n",
    "                                      vaccines_df.estabelecimento_razaosocial == health_institution_table_DF.organization])\r\n",
    "\r\n",
    "vaccines_df_joined.printSchema()"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create Patient table and write parquet files\r\n",
    "vaccines_df_joined.createOrReplaceTempView(\"imunization_table_DF\")\r\n",
    "imunization_table_DF = spark.sql(\"\"\"\r\n",
    "    SELECT distinct paciente_id AS patient_id,\r\n",
    "            id AS health_institution_id,\r\n",
    "            vacina_categoria_codigo AS category_id,\r\n",
    "            vacina_grupoatendimento_codigo AS population_group_id,\r\n",
    "            vacina_codigo AS vaccines_id,\r\n",
    "            vacina_dataaplicacao AS jab_date\r\n",
    "        FROM imunization_table_DF\r\n",
    "        ORDER BY jab_date\r\n",
    "\"\"\")\r\n",
    "\r\n",
    "imunization_table_DF.printSchema()"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write parquet file and get back to Spark:\r\n",
    "write_parquet(imunization_table_DF, 'imunization')\r\n",
    "imunization_table_DF = read_parquet('imunization')"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "imunization_table_DF.show()"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e3babd7ac79e0887df5a9e3ee8123f217b43f09743b73590444977beefbb8a7a"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}